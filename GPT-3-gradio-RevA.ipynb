{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_wiki_download.ipynb","provenance":[{"file_id":"1qOb3NkwpJE3pzxMGk1qgnvQsc63AEvsy","timestamp":1615886943370}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOQgEqtyrdaHDu6p3QewScT"},"kernelspec":{"name":"python3","display_name":"Python 3.7.2 64-bit","metadata":{"interpreter":{"hash":"3a8c797cea816b776118a7a74732541a79826f336be5891ea067e9fc65047e29"}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Cg6_0Te6XQfI"},"source":["# Mounting google-drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZGLl0TuXPSC","executionInfo":{"status":"ok","timestamp":1615887007555,"user_tz":-60,"elapsed":23917,"user":{"displayName":"Mark Lina","photoUrl":"","userId":"17651129667533642938"}},"outputId":"9ff4fbf5-fa87-4c5b-af78-9481ad477893"},"source":["#start by mounting google drive\r\n","from google.colab import drive, files\r\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vj-2UbtHY47a"},"source":["# 1. Installing required libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install openai\n","!pip install gradio\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import openai\n","import gradio as gr\n","\n","openai.api_key = \"XXXXXXXX\"\n","print(openai.Model.list())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def gpt_output(prompt):\n","    # prompt=\"First response from model\"\n","    response= openai.Completion.create(\n","        model=\"text-davinci-003\",\n","        prompt=prompt,\n","        temperature=0.9,\n","        max_tokens=150,\n","        top_p=1,\n","        frequency_penalty=0,\n","        presence_penalty=0.6,\n","        stop=[\" Human :\", \" AI:\"]\n","\n","        )\n","        print(\"\\n --- Model response: ---\",response.choices[0].text)\n","    return response.choices[0].text\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prompt=\"First response from model\"\n","gpt_output(prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["while True:\n","    query = input(\"Ask me a question:\\n \")\n","    gpt_output(query)"]},{"cell_type":"markdown","metadata":{"id":"kQl0bIwkc3rP"},"source":["# 2. Gradio-front-end for chatboot"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def gpt_output_1(prompt):\n","    # prompt=\"First response from model\"\n","    response= openai.Completion.create(\n","        model=\"text-davinci-003\",\n","        prompt=prompt,\n","        temperature=0.9,\n","        max_tokens=150,\n","        top_p=1,\n","        frequency_penalty=0,\n","        presence_penalty=0.6,\n","        stop=[\" Human :\", \" Model:\"]\n","\n","        )\n","        # print(\"\\n --- Model response: ---\",response.choices[0].text)\n","    return response.choices[0].text"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def chat_gpt_clone(input, history):\n","    history = history or []\n","    s= list(sum(history, ()))\n","    s.append(input)\n","    inp = ''.join(s)\n","    output = gpt_output_1(inp)\n","    history.append((input, output))\n","    return history, history"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[" block - gr.Blocks()\n"," with block:\n","     \n","     gr.Markdown(\"\"\"<h1><center> --- That is your virtual assistent --- </center></h1>\"\"\")\n","     chatboot = gr.Chatboot()\n","     message  = gr.textboox(placeholder=prompt)\n","     state    = gr.State()\n","     submit   = gr.Button(\"SEND\")\n","\n","     submit.click(gpt_output_1, inputs-[message, state], outputs=[chatboot, state])\n","block.launch(debug=True, share=True) # share=True creating public link"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"gseX4EVPm681"},"source":["# 3. TTS"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install pyttsx3\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import  pyttsx3 # converting text data into speech TTS"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["engine = pyttsx3.init()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def speak(text):\n","    engine.say(text)\n","    engine.runAndWait()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["text=' Hi am the virtual assistant'\n","speak(text)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["start_sequence =\"\\n Model:\"\n","restart_sequence= \"\\Human:\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def gpt_output_2(prompt,):\n","    # prompt=\"First response from model\"\n","    response= openai.Completion.create(\n","        model=\"text-davinci-003\",\n","        prompt=prompt,\n","        temperature=0.9,\n","        max_tokens=150,\n","        top_p=1,\n","        frequency_penalty=0,\n","        presence_penalty=0.6,\n","        stop=[\" Human :\", \" Model:\"]\n","\n","        )\n","        print(\"\\n --- Model response: ---\",response.choices[0].text)\n","        data = response.choices[0].text\n","        speak(data)\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["while True:\n","    query = input(\"Ask me a question:\\n \")\n","    gpt_output_2(query)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install SpeechRecognition"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import speech_recognition as sr"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def STT():\n","    r = sr.Recognizer()\n","    with sr.Microphone() as source:\n","        print(\"Ask/tell me something...\")\n","        r.pause_treshold =1 \n","        audio = r.listen( source)\n","    try:\n","        print(\"recognizing ...\")\n","        query =r.recognize_google(audio, language=\"en-US\")\n","        print(\"you said:\"+query)\n","    except: Exception as e: \n","        print(e)\n","        speak( \"please say it again\")\n","    return query\n","\n","         "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["while True:\n","    query = STT()\n","    gpt_output_2(query)"]},{"source":["# 4 Saving to hdf5 file for later use if there is need"],"cell_type":"code","metadata":{"id":"yzX4fM94ul-7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UxniNZlcqC--"},"source":["Now when having text to pump into GPT lets go there..."]}]}